<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>4. Results</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Introduction to Neural Networks</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Presentation
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="architectures.html">Architectures</a>
    </li>
    <li>
      <a href="linear_algebra.html">Linear algebra</a>
    </li>
    <li>
      <a href="results.html">Results</a>
    </li>
    <li>
      <a href="comparison.html">Comparison</a>
    </li>
    <li>
      <a href="applicability.html">Applicability</a>
    </li>
    <li>
      <a href="references.html">References</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">4. Results</h1>

</div>


<p>
 
</p>
<p>
 
</p>
<p>One of the most popular high-level libraries for building machine learning models is <strong>Keras</strong>. In addition to Keras, we have also used ggplot2 for creating visualizations:</p>
<div id="data-loading-and-preparation" class="section level5">
<h5>Data loading and preparation</h5>
<p>As covered in the Problem section, the group used the MNIST Fashion dataset for training a model to classify clothing items:</p>
<p>We can also prepare a vector of the possible classes the model will attempt to classify samples as:</p>
<pre class="r"><code>classes = c(&#39;T-shirt/top&#39;,
            &#39;Trouser&#39;,
            &#39;Pullover&#39;,
            &#39;Dress&#39;,
            &#39;Coat&#39;,
            &#39;Sandal&#39;,
            &#39;Shirt&#39;,
            &#39;Sneaker&#39;,
            &#39;Bag&#39;,
            &#39;Ankle boot&#39;)</code></pre>
</div>
<div id="data-exploration" class="section level5">
<h5>Data exploration</h5>
<p>According to official documentation, there should be 60000 28 x 28 training images along with 60000 labels and 10000 28 x 28 test images along with 10000 test labels:</p>
<pre class="r"><code>dim(train_images)</code></pre>
<pre><code>## [1] 60000    28    28</code></pre>
<pre class="r"><code>dim(train_labels)</code></pre>
<pre><code>## [1] 60000</code></pre>
<pre class="r"><code>dim(test_images)</code></pre>
<pre><code>## [1] 10000    28    28</code></pre>
<pre class="r"><code>dim(test_labels)</code></pre>
<pre><code>## [1] 10000</code></pre>
<p>We can also plot a sample image of an item:</p>
<pre class="r"><code>sample_image &lt;- as.data.frame(train_images[666, , ])
colnames(sample_image) &lt;- seq_len(ncol(sample_image))
sample_image$y &lt;- seq_len(nrow(sample_image))
sample_image &lt;- gather(sample_image, &quot;x&quot;, &quot;value&quot;, -y)
sample_image$x &lt;- as.integer(sample_image$x)

p &lt;- ggplot(sample_image, aes(x=x, y=y, fill=value)) +
    geom_tile() +
    scale_fill_gradient(low=&quot;white&quot;, high=&quot;black&quot;, na.value=NA) +
    scale_y_reverse() +
    theme_minimal() +
    theme(panel.grid=element_blank()) +
    theme(aspect.ratio=1) +
    xlab(&quot;&quot;) +
    ylab(&quot;&quot;)
print(p)</code></pre>
<p><img src="results_files/figure-html/unnamed-chunk-5-1.png" width="960" /></p>
</div>
<div id="training" class="section level5">
<h5>Training</h5>
<p><strong>Neural networks</strong> deal more gracefully with values that are scaled to be between 0 and 1. The reason is large ranges, such as 0 to 255, can cause large perturbations in the output of the network because the values are large:</p>
<pre class="r"><code>train_images &lt;- train_images/255
test_images &lt;- test_images/255</code></pre>
<p>We can inspect a subset of the images to make sure they are in the expected format and have the correct labels based on visual inspection:</p>
<pre class="r"><code>par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs=&#39;i&#39;, yaxs=&#39;i&#39;)
for(i in 42:66) {
    img &lt;- train_images[i, , ]
    img &lt;- t(apply(img, 2, rev))
    image(1:28, 1:28, img, col=gray((0:255)/255), xaxt=&#39;n&#39;, yaxt=&#39;n&#39;,
          main=paste(classes[train_labels[i] + 1]))
}</code></pre>
<p><img src="results_files/figure-html/unnamed-chunk-7-1.png" width="960" /></p>
<p>Now, we begin to build our model and establish our layers, which will start by shrinking the first layer into 512 values. After this layer has been evaluated by the sigmoid activation function, it will produce another level of 512 values, which goes through a different activation function (ReLU) before being sent to the final layer of ten values:</p>
<pre class="r"><code>model &lt;- keras_model_sequential()
model %&gt;%
    layer_flatten(input_shape=c(28, 28)) %&gt;%
    layer_dense(units=512, activation=&#39;sigmoid&#39;) %&gt;%
    layer_dropout(0.2) %&gt;%
    layer_dense(units=512, activation=&#39;relu&#39;)%&gt;%
    layer_dropout(0.2) %&gt;%
    layer_dense(units=10, activation=&#39;softmax&#39;)</code></pre>
<p>After establishing the layers, and during the compilation of the model, we must include some preliminary steps: <strong>the loss function, optimizer, and metrics</strong>. The <em>loss function</em> measure the difference between a given true label and the prediction of the network. The model uses the <em>optimizer</em> to update itself based on the data and loss function; adam specifically uses a <em>gradient-based optimization</em>. <em>Metrics</em> are what monitor the training and testing steps.</p>
<pre class="r"><code>model %&gt;% compile(optimizer=&#39;adam&#39;,
                  loss=&#39;sparse_categorical_crossentropy&#39;,
                  metrics=c(&#39;accuracy&#39;))</code></pre>
<p>With all of this set up, we are finally able to train our neural network. The “epochs” option determine how many cycles we let the network train upon. Here, we will train the network for 50 epochs. However, after 25 epochs, we notice the performance of the network degrading on the validation dataset, which is potentially caused by overfitting. Twenty fice epochs should be sufficient for getting a network that performs well. We can obtain metrics such as accuracy and loss while the netowkr is training; this option can be turned off by setting the keyword argument <strong>verbose=FALSE</strong>.</p>
<pre class="r"><code>epochs &lt;- 50
history &lt;- model %&gt;% fit(train_images, train_labels,
                         epochs=epochs,
                         batch_size=128,
                         validation_data=list(test_images, test_labels),
                         view_metrics=FALSE)</code></pre>
</div>
<div id="prediction-results" class="section level5">
<h5>Prediction results</h5>
<p>After training the model, we can make some predictions with the set of test images (i.e., the model predicts the label for each image in correspondence to the 10 classes we had previously outlined). The highest value in the output distribution is what tells us what the model’s prediction is.</p>
<pre class="r"><code>prediction &lt;- model %&gt;% predict_classes(test_images)
prediction[1:20]</code></pre>
<pre><code>##  [1] 9 2 1 1 6 1 4 6 5 7 4 5 5 3 4 1 2 2 8 0</code></pre>
<pre class="r"><code>test_labels[1:20]</code></pre>
<pre><code>##  [1] 9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0</code></pre>
<p>For our last trick, we show the prediction results from a subset of the data visually. Correct predictions will show up with green text and wrong predictions will be shown with red text.</p>
<pre class="r"><code>par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs=&#39;i&#39;, yaxs=&#39;i&#39;)
for (i in 1:epochs) {
  img &lt;- test_images[i, , ]
  img &lt;- t(apply(img, 2, rev))
  if (prediction[i] == test_labels[i]) {
    color &lt;- &#39;#34FE82&#39;
  } else {
    color &lt;- &#39;#FF5567&#39;
  }
  image(1:28, 1:28, img, col=gray((0:255)/255), xaxt=&#39;n&#39;, yaxt=&#39;n&#39;,
        main = paste0(classes[prediction[i] + 1], &quot; (&quot;,
                      classes[test_labels[i] + 1], &quot;)&quot;),
        col.main = color)
}</code></pre>
<p><img src="results_files/figure-html/unnamed-chunk-12-1.png" width="960" /><img src="results_files/figure-html/unnamed-chunk-12-2.png" width="960" /></p>
</div>
<div id="sample-accuracy-and-loss-plots-from-the-training-process" class="section level5">
<h5>Sample accuracy and loss plots from the training process</h5>
<pre class="r"><code>train_acc &lt;- history$metrics$accuracy
train_loss &lt;- history$metrics$loss
val_acc &lt;- history$metrics$val_accuracy
val_loss &lt;- history$metrics$val_loss

acc &lt;- data.frame(train_acc=train_acc, val_acc=val_acc)
loss &lt;- data.frame(train_loss=train_loss, val_loss=val_loss)

ggplot(data=acc, aes(1:epochs, train_acc, color=&quot;blue&quot;)) + 
  geom_point() + # Starman, this is weird
  geom_point(data=acc, aes(1:epochs, val_acc, color=&quot;red&quot;)) +
  theme_classic() +
  geom_vline(xintercept=epochs/2, linetype=&quot;dotted&quot;, color=&quot;black&quot;, size=1.5) +
  labs(title=&quot;Training and validation accuracy during training&quot;, 
       x=&quot;Epoch&quot;, 
       y=&quot;Accuracy&quot;, 
       color=&quot;Dataset&quot;) +
  scale_color_manual(labels=c(&quot;Training&quot;, &quot;Validation&quot;), values=c(&quot;blue&quot;, &quot;red&quot;)) + 
  theme(plot.title=element_text(size=20, face=&quot;bold&quot;))</code></pre>
<p><img src="results_files/figure-html/unnamed-chunk-13-1.png" width="960" /></p>
<pre class="r"><code>ggplot(data=loss, aes(1:epochs, train_loss, color=&quot;blue&quot;)) + 
  geom_point() + # Starman, this is weird
  geom_point(data=loss, aes(1:epochs, val_loss, color=&quot;red&quot;)) +
  theme_classic() +
  geom_vline(xintercept=epochs/2, linetype=&quot;dotted&quot;, color=&quot;black&quot;, size=1.5) +
  labs(title=&quot;Training and validation loss during training&quot;, 
       x=&quot;Epoch&quot;, 
       y=&quot;Loss&quot;, 
       color=&quot;Dataset&quot;) +
  scale_color_manual(labels=c(&quot;Training&quot;, &quot;Validation&quot;), values=c(&quot;blue&quot;, &quot;red&quot;)) + 
  theme(plot.title=element_text(size=20, face=&quot;bold&quot;))</code></pre>
<p><img src="results_files/figure-html/unnamed-chunk-13-2.png" width="960" /></p>
<p>The plot of training and validation accuracy showcases how accuracy increases during training. Similarly, the plot of trianing and validation loss showcases how loss suggesting the network is getting better at minimizing the difference between a true answer and a predicted answer. The increase in accuracy and the decrease in loss are both consequence of the network getting better as training progresses. During trials, we found that training for 25 epochs is sufficient - the optimal epoch limit is marked in the plots.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
